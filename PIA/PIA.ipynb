{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91c7896d-5806-41fb-a3e5-3954a666d53b",
   "metadata": {},
   "source": [
    "# PIA \n",
    "## Extraccion de caracteristicas de los nombres de cada archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a2bfce90-7374-45e2-bb13-0f8c914fb6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99535188-9559-45ed-9067-a3db9e528653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio raíz del dataset\n",
    "dataset_path = './'  # Asumimos que estás corriendo en el mismo nivel que las carpetas Actor_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "70ea91f9-abc1-4e12-a1b3-f4d8d3502910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de emociones\n",
    "emotion_dict = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\"\n",
    "}\n",
    "\n",
    "# Lista para guardar registros\n",
    "data = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6dd016de-10c2-4dd5-9e97-cf1be447854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones de aumento\n",
    "def change_pitch(audio, sr, pitch_factor=2.0):\n",
    "    return librosa.effects.pitch_shift(audio, sr=sr, n_steps=pitch_factor)\n",
    "\n",
    "def time_stretch(audio, rate=0.9):\n",
    "    return librosa.effects.time_stretch(y=audio, rate=rate)\n",
    "\n",
    "\n",
    "def add_noise(audio, noise_factor=0.005):\n",
    "    noise = np.random.randn(len(audio))\n",
    "    return audio + noise_factor * noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506cb885-8edb-4218-98f3-ba658adde047",
   "metadata": {},
   "source": [
    "- Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "- Vocal channel (01 = speech, 02 = song).\n",
    "- Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "- Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "- Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "- Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "- Actor (01 to 24. Odd numbered actors are male, even numbered actors are female)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "29717671-769c-4ac9-8cc0-5d4ac9b418fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recorrer carpetas y procesar audios\n",
    "for folder in os.listdir(dataset_path):\n",
    "    if folder.startswith(\"Actor_\"):\n",
    "        folder_path = os.path.join(dataset_path, folder)\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".wav\"):\n",
    "                parts = file.split(\".\")[0].split(\"-\")\n",
    "                emotion_code = parts[2]\n",
    "                intensity_code = parts[3]\n",
    "                actor_id = int(parts[-1])\n",
    "\n",
    "                emotion = emotion_dict[emotion_code]\n",
    "                intensity = \"normal\" if intensity_code == \"01\" else \"strong\"\n",
    "                gender = \"male\" if actor_id % 2 != 0 else \"female\"\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "\n",
    "                # Agregar original (con audio en disco)\n",
    "                data.append({\n",
    "                    \"file_path\": file_path,\n",
    "                    \"audio\": None,\n",
    "                    \"sr\": None,\n",
    "                    \"emotion\": emotion,\n",
    "                    \"intensity\": intensity,\n",
    "                    \"gender\": gender,\n",
    "                    \"actor_id\": actor_id,\n",
    "                    \"augmentation\": \"original\"\n",
    "                })\n",
    "\n",
    "                try:\n",
    "                    audio, sr = librosa.load(file_path)\n",
    "\n",
    "                    # Aumento 1: pitch\n",
    "                    pitch_audio = change_pitch(audio, sr)\n",
    "                    data.append({\n",
    "                        \"file_path\": None,\n",
    "                        \"audio\": pitch_audio,\n",
    "                        \"sr\": sr,\n",
    "                        \"emotion\": emotion,\n",
    "                        \"intensity\": intensity,\n",
    "                        \"gender\": gender,\n",
    "                        \"actor_id\": actor_id,\n",
    "                        \"augmentation\": \"pitch\"\n",
    "                    })\n",
    "\n",
    "                    # Aumento 2: stretch\n",
    "                    stretched_audio = time_stretch(audio)\n",
    "                    data.append({\n",
    "                        \"file_path\": None,\n",
    "                        \"audio\": stretched_audio,\n",
    "                        \"sr\": sr,\n",
    "                        \"emotion\": emotion,\n",
    "                        \"intensity\": intensity,\n",
    "                        \"gender\": gender,\n",
    "                        \"actor_id\": actor_id,\n",
    "                        \"augmentation\": \"stretch\"\n",
    "                    })\n",
    "\n",
    "                    # Aumento 3: ruido\n",
    "                    noisy_audio = add_noise(audio)\n",
    "                    data.append({\n",
    "                        \"file_path\": None,\n",
    "                        \"audio\": noisy_audio,\n",
    "                        \"sr\": sr,\n",
    "                        \"emotion\": emotion,\n",
    "                        \"intensity\": intensity,\n",
    "                        \"gender\": gender,\n",
    "                        \"actor_id\": actor_id,\n",
    "                        \"augmentation\": \"noise\"\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error con archivo {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5d12052b-2241-4e32-b329-decbdf88a321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y guardar el DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"ravdess_metadata.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ee5b3cfd-6143-4552-907b-9fd18d1a6667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "      <th>gender</th>\n",
       "      <th>actor_id</th>\n",
       "      <th>augmentation</th>\n",
       "      <th>audio</th>\n",
       "      <th>sr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./Actor_01\\03-01-01-01-01-01-01.wav</td>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>original</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>pitch</td>\n",
       "      <td>[3.1423087e-07, -3.197933e-07, 3.260547e-07, -...</td>\n",
       "      <td>22050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>stretch</td>\n",
       "      <td>[6.719997e-08, -2.8142479e-08, 1.5973922e-09, ...</td>\n",
       "      <td>22050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>noise</td>\n",
       "      <td>[8.595426389673514e-05, 0.0005436920150429574,...</td>\n",
       "      <td>22050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./Actor_01\\03-01-01-01-01-02-01.wav</td>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>original</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             file_path  emotion intensity gender  actor_id  \\\n",
       "0  ./Actor_01\\03-01-01-01-01-01-01.wav  neutral    normal   male         1   \n",
       "1                                  NaN  neutral    normal   male         1   \n",
       "2                                  NaN  neutral    normal   male         1   \n",
       "3                                  NaN  neutral    normal   male         1   \n",
       "4  ./Actor_01\\03-01-01-01-01-02-01.wav  neutral    normal   male         1   \n",
       "\n",
       "  augmentation                                              audio       sr  \n",
       "0     original                                                NaN      NaN  \n",
       "1        pitch  [3.1423087e-07, -3.197933e-07, 3.260547e-07, -...  22050.0  \n",
       "2      stretch  [6.719997e-08, -2.8142479e-08, 1.5973922e-09, ...  22050.0  \n",
       "3        noise  [8.595426389673514e-05, 0.0005436920150429574,...  22050.0  \n",
       "4     original                                                NaN      NaN  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar resumen\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b2e3ce-c1d2-43e2-baf7-dff942473316",
   "metadata": {},
   "source": [
    "## Extracción de caracteristicas de cada Audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "70736788-ac7f-4764-a14b-1f40794ae095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "214eaa2e-84e0-45a1-b379-ca672d96cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_unificado(row):\n",
    "    try:\n",
    "        if row[\"augmentation\"] == \"original\":\n",
    "            y, sr = librosa.load(row[\"file_path\"], sr=None)\n",
    "        else:\n",
    "            y = row[\"audio\"]\n",
    "            sr = row[\"sr\"]\n",
    "\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        mfcc_mean = np.mean(mfcc, axis=1)\n",
    "        mfcc_std = np.std(mfcc, axis=1)\n",
    "        features = np.concatenate([mfcc_mean, mfcc_std])\n",
    "        return features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error con archivo {row.get('file_path', 'AUMENTADO')} / tipo {row['augmentation']}: {e}\")\n",
    "        return np.zeros(26)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f8ede303-f4d1-4b33-9d59-6cd0a626911a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11520/11520 [02:35<00:00, 73.93it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "features = df.progress_apply(extract_features_unificado, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d1ed119b-c0f3-4816-879d-27090719245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame(features.tolist())\n",
    "features_df.columns = [f\"mfcc_{i}\" for i in range(1, 27)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "896f7d57-a3b9-4cd5-a5af-4886f0ad3afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir con etiquetas\n",
    "full_df = pd.concat([features_df, df[[\"emotion\"]].reset_index(drop=True)], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "efa34a4a-dd16-4d38-834d-ad752a3122cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc_1</th>\n",
       "      <th>mfcc_2</th>\n",
       "      <th>mfcc_3</th>\n",
       "      <th>mfcc_4</th>\n",
       "      <th>mfcc_5</th>\n",
       "      <th>mfcc_6</th>\n",
       "      <th>mfcc_7</th>\n",
       "      <th>mfcc_8</th>\n",
       "      <th>mfcc_9</th>\n",
       "      <th>mfcc_10</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_18</th>\n",
       "      <th>mfcc_19</th>\n",
       "      <th>mfcc_20</th>\n",
       "      <th>mfcc_21</th>\n",
       "      <th>mfcc_22</th>\n",
       "      <th>mfcc_23</th>\n",
       "      <th>mfcc_24</th>\n",
       "      <th>mfcc_25</th>\n",
       "      <th>mfcc_26</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-726.217224</td>\n",
       "      <td>68.541420</td>\n",
       "      <td>3.293398</td>\n",
       "      <td>12.205300</td>\n",
       "      <td>5.510278</td>\n",
       "      <td>13.667410</td>\n",
       "      <td>-2.983828</td>\n",
       "      <td>3.098029</td>\n",
       "      <td>-3.310813</td>\n",
       "      <td>-1.564384</td>\n",
       "      <td>...</td>\n",
       "      <td>13.634708</td>\n",
       "      <td>19.163044</td>\n",
       "      <td>14.063682</td>\n",
       "      <td>8.619501</td>\n",
       "      <td>10.998984</td>\n",
       "      <td>8.348630</td>\n",
       "      <td>12.845314</td>\n",
       "      <td>7.708874</td>\n",
       "      <td>8.651435</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-742.924805</td>\n",
       "      <td>54.153629</td>\n",
       "      <td>-1.021684</td>\n",
       "      <td>14.067798</td>\n",
       "      <td>2.208796</td>\n",
       "      <td>-2.997830</td>\n",
       "      <td>-7.191713</td>\n",
       "      <td>-6.332038</td>\n",
       "      <td>-11.387864</td>\n",
       "      <td>3.942475</td>\n",
       "      <td>...</td>\n",
       "      <td>14.310036</td>\n",
       "      <td>13.388592</td>\n",
       "      <td>13.856584</td>\n",
       "      <td>13.237471</td>\n",
       "      <td>16.083012</td>\n",
       "      <td>9.576642</td>\n",
       "      <td>9.777632</td>\n",
       "      <td>9.878550</td>\n",
       "      <td>5.751151</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-733.570190</td>\n",
       "      <td>54.273224</td>\n",
       "      <td>0.259147</td>\n",
       "      <td>12.671712</td>\n",
       "      <td>7.179569</td>\n",
       "      <td>0.662815</td>\n",
       "      <td>-3.471071</td>\n",
       "      <td>-3.802527</td>\n",
       "      <td>-12.115388</td>\n",
       "      <td>-3.410399</td>\n",
       "      <td>...</td>\n",
       "      <td>16.956284</td>\n",
       "      <td>14.008063</td>\n",
       "      <td>11.031326</td>\n",
       "      <td>12.343883</td>\n",
       "      <td>17.463345</td>\n",
       "      <td>9.055738</td>\n",
       "      <td>8.345324</td>\n",
       "      <td>9.922368</td>\n",
       "      <td>10.208949</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-307.917390</td>\n",
       "      <td>6.168475</td>\n",
       "      <td>4.837421</td>\n",
       "      <td>3.978016</td>\n",
       "      <td>2.255884</td>\n",
       "      <td>-0.090857</td>\n",
       "      <td>-1.050032</td>\n",
       "      <td>-2.436418</td>\n",
       "      <td>-3.433082</td>\n",
       "      <td>-2.553736</td>\n",
       "      <td>...</td>\n",
       "      <td>6.087761</td>\n",
       "      <td>4.197568</td>\n",
       "      <td>4.140401</td>\n",
       "      <td>5.066715</td>\n",
       "      <td>5.162981</td>\n",
       "      <td>4.339493</td>\n",
       "      <td>4.795025</td>\n",
       "      <td>5.180180</td>\n",
       "      <td>4.499706</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-719.128296</td>\n",
       "      <td>70.201569</td>\n",
       "      <td>1.168397</td>\n",
       "      <td>13.122543</td>\n",
       "      <td>7.836950</td>\n",
       "      <td>14.411290</td>\n",
       "      <td>-4.111360</td>\n",
       "      <td>4.468973</td>\n",
       "      <td>-3.539367</td>\n",
       "      <td>-3.658607</td>\n",
       "      <td>...</td>\n",
       "      <td>12.449026</td>\n",
       "      <td>19.218317</td>\n",
       "      <td>14.516836</td>\n",
       "      <td>8.057330</td>\n",
       "      <td>11.509418</td>\n",
       "      <td>8.151206</td>\n",
       "      <td>12.590632</td>\n",
       "      <td>7.271216</td>\n",
       "      <td>8.202284</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mfcc_1     mfcc_2    mfcc_3     mfcc_4    mfcc_5     mfcc_6    mfcc_7  \\\n",
       "0 -726.217224  68.541420  3.293398  12.205300  5.510278  13.667410 -2.983828   \n",
       "1 -742.924805  54.153629 -1.021684  14.067798  2.208796  -2.997830 -7.191713   \n",
       "2 -733.570190  54.273224  0.259147  12.671712  7.179569   0.662815 -3.471071   \n",
       "3 -307.917390   6.168475  4.837421   3.978016  2.255884  -0.090857 -1.050032   \n",
       "4 -719.128296  70.201569  1.168397  13.122543  7.836950  14.411290 -4.111360   \n",
       "\n",
       "     mfcc_8     mfcc_9   mfcc_10  ...    mfcc_18    mfcc_19    mfcc_20  \\\n",
       "0  3.098029  -3.310813 -1.564384  ...  13.634708  19.163044  14.063682   \n",
       "1 -6.332038 -11.387864  3.942475  ...  14.310036  13.388592  13.856584   \n",
       "2 -3.802527 -12.115388 -3.410399  ...  16.956284  14.008063  11.031326   \n",
       "3 -2.436418  -3.433082 -2.553736  ...   6.087761   4.197568   4.140401   \n",
       "4  4.468973  -3.539367 -3.658607  ...  12.449026  19.218317  14.516836   \n",
       "\n",
       "     mfcc_21    mfcc_22   mfcc_23    mfcc_24   mfcc_25    mfcc_26  emotion  \n",
       "0   8.619501  10.998984  8.348630  12.845314  7.708874   8.651435  neutral  \n",
       "1  13.237471  16.083012  9.576642   9.777632  9.878550   5.751151  neutral  \n",
       "2  12.343883  17.463345  9.055738   8.345324  9.922368  10.208949  neutral  \n",
       "3   5.066715   5.162981  4.339493   4.795025  5.180180   4.499706  neutral  \n",
       "4   8.057330  11.509418  8.151206  12.590632  7.271216   8.202284  neutral  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar\n",
    "full_df.to_csv(\"ravdess_features.csv\", index=False)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "27be49ab-dcd2-4d70-9ba7-eb66ada0d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0e3e6063-977d-4036-92fc-b1d7ecc24d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración\n",
    "n_mfcc = 13\n",
    "max_pad_len = 173  # Se usará para hacer padding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "23879cda-3b28-422d-ae3c-760f710acc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para extraer MFCC secuencial y aplicar padding\n",
    "def extract_mfcc_sequence(file_path, max_pad_len=173):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    if mfcc.shape[1] < max_pad_len:\n",
    "        pad_width = max_pad_len - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mfcc = mfcc[:, :max_pad_len]\n",
    "    return mfcc.T  # Transpuesta para que sea [frames, n_mfcc]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1520d577-b601-41cd-95c5-ca5f24b497f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc_sequence_unificado(row, max_pad_len=173):\n",
    "    try:\n",
    "        if row[\"augmentation\"] == \"original\":\n",
    "            y, sr = librosa.load(row[\"file_path\"], sr=None)\n",
    "        else:\n",
    "            y = row[\"audio\"]\n",
    "            sr = row[\"sr\"]\n",
    "\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "\n",
    "        # Padding para igualar longitud\n",
    "        if mfcc.shape[1] < max_pad_len:\n",
    "            pad_width = max_pad_len - mfcc.shape[1]\n",
    "            mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            mfcc = mfcc[:, :max_pad_len]\n",
    "\n",
    "        return mfcc\n",
    "    except Exception as e:\n",
    "        print(f\"Error con archivo {row.get('file_path', 'AUMENTADO')} / tipo {row['augmentation']}: {e}\")\n",
    "        return np.zeros((13, max_pad_len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "205c9f87-a9f3-4eb2-8cc3-d86c1b321ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6d6fff3d-4065-4ede-ae50-ba21645bf6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11520/11520 [02:03<00:00, 93.45it/s]\n"
     ]
    }
   ],
   "source": [
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    mfcc_seq = extract_mfcc_sequence_unificado(row, max_pad_len=173)\n",
    "    X.append(mfcc_seq)\n",
    "    y.append(row[\"emotion\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "199786ad-6881-4132-b5fb-b92e36d0a381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de X: (11520, 13, 173)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "print(\"Forma de X:\", X.shape)  # [n_samples, frames, n_mfcc]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a3408a41-5527-4e5e-815d-4a1451b9b586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases: ['angry' 'calm' 'disgust' 'fearful' 'happy' 'neutral' 'sad' 'surprised']\n"
     ]
    }
   ],
   "source": [
    "# Codificamos etiquetas\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "print(\"Clases:\", le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "151cee18-2584-467f-93cc-219439346bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Masking, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f23c0918-8b6b-4f08-b62c-de7e9e834923",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "52933e4c-b6b5-4c56-af0f-8bf2dbfc9f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(X.shape[1], X.shape[2])))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(y_categorical.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e7269398-74f6-4271-9b42-aed36b588b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083ad206-523d-4397-a461-b1ca06657c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.2137 - loss: 1.9747 - val_accuracy: 0.3394 - val_loss: 1.7509\n",
      "Epoch 2/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.3479 - loss: 1.7080 - val_accuracy: 0.3542 - val_loss: 1.7228\n",
      "Epoch 3/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4040 - loss: 1.5633 - val_accuracy: 0.3911 - val_loss: 1.5797\n",
      "Epoch 4/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.4624 - loss: 1.4514 - val_accuracy: 0.4149 - val_loss: 1.5446\n",
      "Epoch 5/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4916 - loss: 1.3719 - val_accuracy: 0.4479 - val_loss: 1.4807\n",
      "Epoch 6/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.5184 - loss: 1.2748 - val_accuracy: 0.4709 - val_loss: 1.4455\n",
      "Epoch 7/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.5524 - loss: 1.2285 - val_accuracy: 0.4839 - val_loss: 1.3920\n",
      "Epoch 8/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5736 - loss: 1.1508 - val_accuracy: 0.5122 - val_loss: 1.3544\n",
      "Epoch 9/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.5894 - loss: 1.1094 - val_accuracy: 0.4957 - val_loss: 1.3689\n",
      "Epoch 10/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.6053 - loss: 1.0853 - val_accuracy: 0.4991 - val_loss: 1.3833\n",
      "Epoch 11/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.6268 - loss: 1.0397 - val_accuracy: 0.5230 - val_loss: 1.3502\n",
      "Epoch 12/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.6335 - loss: 0.9993 - val_accuracy: 0.5421 - val_loss: 1.2966\n",
      "Epoch 13/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.6768 - loss: 0.9214 - val_accuracy: 0.5560 - val_loss: 1.2623\n",
      "Epoch 14/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.6753 - loss: 0.9175 - val_accuracy: 0.5742 - val_loss: 1.2224\n",
      "Epoch 15/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.6980 - loss: 0.8448 - val_accuracy: 0.5920 - val_loss: 1.2257\n",
      "Epoch 16/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7022 - loss: 0.8458 - val_accuracy: 0.5855 - val_loss: 1.2573\n",
      "Epoch 17/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7178 - loss: 0.7924 - val_accuracy: 0.5864 - val_loss: 1.2185\n",
      "Epoch 18/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7221 - loss: 0.7830 - val_accuracy: 0.5981 - val_loss: 1.2201\n",
      "Epoch 19/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7501 - loss: 0.7231 - val_accuracy: 0.6003 - val_loss: 1.1980\n",
      "Epoch 20/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7458 - loss: 0.7042 - val_accuracy: 0.6246 - val_loss: 1.1797\n",
      "Epoch 21/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.7651 - loss: 0.6621 - val_accuracy: 0.6120 - val_loss: 1.1842\n",
      "Epoch 22/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7714 - loss: 0.6410 - val_accuracy: 0.6597 - val_loss: 1.1107\n",
      "Epoch 23/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7805 - loss: 0.6271 - val_accuracy: 0.6584 - val_loss: 1.0997\n",
      "Epoch 24/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7816 - loss: 0.6260 - val_accuracy: 0.6493 - val_loss: 1.1157\n",
      "Epoch 25/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7886 - loss: 0.6075 - val_accuracy: 0.6623 - val_loss: 1.1458\n",
      "Epoch 26/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7820 - loss: 0.6071 - val_accuracy: 0.6519 - val_loss: 1.1349\n",
      "Epoch 27/50\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7905 - loss: 0.6014 - val_accuracy: 0.6680 - val_loss: 1.0872\n",
      "Epoch 28/50\n",
      "\u001b[1m144/288\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8009 - loss: 0.5834"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Entrenamiento\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca33238-a21d-44d0-a847-3a9b68601339",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"modelo_emociones_rnn.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0205ca4e-b442-457a-932e-79930f5b73ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
